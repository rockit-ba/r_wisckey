> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。
> 下文提到的顺序IO如无特殊说明，均指磁盘顺序IO，因为另还有一种比较普遍的存储介质SSD，它的随机读和顺序读的差别不是很大（注意是读，不包括写），并且可以通过并行查询来进一步弥补这之间的差别。
>
> 通常来说，我们不太倾向于对磁盘IO进行多线程操作，因为它的速率是有上限的，这也就是大多业务系统无论上层如何考虑优化，最后的瓶颈依然会在数据库上面，在数据库这个环节我们只能通过添加机器来解决，没有其它办法，这也是分布式系统出现的重要因素。

凡是涉及开发直接和磁盘存储打交道的低级层面的系统，比如DBMS、消息中间件系统或者文件存储系统，我们避不开的一个概念是 磁盘的顺序IO和随机IO。

比较有意思的一件事是，很多没有类似系统开发从业经验的开发者，通常不能够真正理解所谓磁盘的顺序/随机IO，他们中绝大多数人能够知道这个概念的存在（*包括笔者自己，笔者可能更惨，因为我的专业是思想政治教育，你可能没听过这个专业，没什么所谓啦。我的意思是，我之前甚至不了解磁盘结构和工作原理，因为我直接学习了Java这种高级语言，跳过了计算机基础科学*），也能够知道`磁盘的顺序IO要比随机IO来得更快`这个结论，但是如果深究具体得：如何的数据操作就是顺序IO……

如果读者从事的是高级层面的业务系统开发，在阅读下面的内容之前，可先自己思考一下这个问题，假如你在一场面试中被问到了这个问题。

如果你觉得无法回答，那么你可能错失了一个工作岗位，于是回到家中开始搜索相关的资料，事实上就我的经验来预测，你得不到什么有用的信息。因为网上的回答都大不相同，这些回答中可能涉及到的这样一些东西：磁盘的工作原理、文件指针seek、虚拟内存映射或者Buffer 之类，如果你看的东西下面有其它读者的评论，那就更错乱了。

接下来正文开始，我们需要循序渐进地去探讨这个问题，然后去理解它。

## 磁盘

这里，我们作为前置知识进行说明，这是我们理解问题的核心，有关它的详细说明你可以从任何地方找到，这里会简单地回顾一下。

![1634175952322](C:\Users\Administrator\AppData\Roaming\Typora\typora-user-images\1634175952322.png)

上图是网上copy的一个关于磁盘的物理结构，基于磁盘的一次IO操作磁盘需要执行以下三个步骤：

1. 磁头臂移动将其上的读写磁头移动到正确的磁道上；
2. 盘片旋转将目标扇区移动到读写磁头下方；
3. 数据传出或者传入。

这三步都需要花费时间，也就是寻道时间-->+旋转延迟时间-->+数据传输时间，我们的目的是要减少这些时间，其中步骤二主要取决于磁盘的转速，步骤三取决于磁盘的传输比率，这两个地方我们都不可控，因此我们的关注点放在第一步，恰好，第一步也是整个操作中耗时占比最大的。

在进行下一步之前，我们先来看一下经典的加速对磁盘的访问方案（以下方案在很多教材中可以找到，笔者参考《数据库系统实现第二版》）：

**1-按柱面组织数据**：如果我们在一个柱面上连续的读取所有块，那么只需要一次寻道时间，而忽略其它时间。这样，从磁盘上读写数据的速度就接近于理论上的传输速率。

**2-使用多个磁盘**：如果我们使用多个磁盘来替代一个磁盘，只要磁盘控制器、总线和内存能以 n 倍速率处理数据传输，则使用 n 个磁盘的效果近似于 1 个磁盘执行了 n 次操作。因此使用多个磁盘可以提高系统的性能。

**3-磁盘调度**：让磁盘控制器在若干个请求中选择一个来首先执行，调度大量块请求的一个简单而有效的方法就是电梯算法。我们把磁盘看作是在做横跨磁盘的扫描，从柱面最内圈到最外圈，然后再返回来，正如电梯会从第一层到最顶层，然后从最顶层到最底层，不会出现在中间来回移动。

**4-预取数据**：在某些应用比如数据库系统，可以预测从磁盘请求块的顺序的。因此我们就可以在需要这些块之前就将它们装入主存（参考数据库page预取）。这样做的好处是我们能较好的调度磁盘，比如采用前文的电梯算法来减少访问块所需要的平均时间。

仔细观察上面的四种方案，抛去第二种，我们只关注1,3,4方案，我们会发现一下共同点，那就是`一次请求磁盘只寻道一次`。看着这里你可能会觉得 “这不是废话么……”。

你需要仔细思考一下这句话之外的含义。

## `顺序`IO

当我们在说顺序IO的时候，我们说的这个顺序到底指的是什么？

加速对磁盘访问的方案，无论是按柱面组织数据、磁盘调度、还是预取数据，他们的核心思想就是在一次 寻道之后，在进行下一次寻道之前尽可能多地查询数据，以减少寻道次数。这其实就是所谓的顺序IO。

就我们上层应用来说，顺序IO和随机IO是一个相辅相成的概念，就像美和丑，对和错，假如世界上只有一个人，我们不能说这个人是美还是丑；太阳一直在运动，我们不能说这个运动是对的还是错的。

同样的，就`单次磁盘IO`来说，我们不能说这次IO是顺序的还是随机的，这需要一个参照物。

加入我们的a文件中有100字节的数据，要读取这100 字节的数据，我们有两种读取的方式：

1. 一次性读取100字节
2. 第一次调用读取0-50字节的数据，然后我们又调用一次读取51-100字节的数据

对比这两种读取方式来说，第一种方式就是顺序读，第二种方式是一种随机读。因此，顺序 是一种策略方式，而不是一个操作。到这里你应该不难理解有些文章中会提及到buffer 或者mmap等东西了，他们可以将多次数据刷盘缓冲到一次（当然mmap可能还涉及了操作系统数据传输优化的问题）。

说到这里，读者应该能够理解了，但是可能还是会有疑问：

“道理是这个道理，但具体实践是如何的？”

## 实践解析

这里我给出两个例子：数据库的page读取和LSM-tree的演进。

### 顺序读：page 读取

一般的传统的关系型数据库都是以page 管理数据的。简单地说，page里面存放了我们保存的tuple数据，当然这不是全部，有时也称为block，那是一个东西。

当我们的上层应用要查找某一条tuple的时候，数据库会找到存放这条tuple的page，直接把这个page加载到内存，这个page中明显不止一条tuple（就MySQL来说，一个满page至少要有两条tuple，保证它的b_tree不会退化为链表），因为数据库预测接下来可能会有查询用到这个tuple周围的tuple，如果确实是这样，那么下一次查询就直接从内存找打返回，而不需要再次磁盘IO。

同样的，数据库还会根据查询计划对连续的page进行预取，这表示，后面的查询可能需要这个page周围的page。

### LSM-tree

> 关于日志结构存储，有兴趣的读者可以找相关资料学习像LSM综述和wisckey论文，这里只做简单的介绍。

在现在的一些新兴数据库，很多采用这个方式作为存储引擎基本结构，它主要利用磁盘的顺序写提供传统关系型数据库达不到的数据插入并发，主要思想是所有的操作都是append一个操作记录，而不是找到原来的数据更新或者删除原来的数据，然后后台合并操作去除重复和过期数据。比如LevelDB、RocksDB、HBase等等。

朴素的LSM的做法是：接收数据，写WAL日志，然后把数据按照数据key在内存中排序，当达到一定容量之后（比如2M）刷到磁盘，这样范围查找的时候可以使用顺序IO 的方式：

比如我们要查找key在0-100 的数据，因为这些数据都是按照key排序之后刷到磁盘中的，我们可以在寻道一次之后一次性读取需要的数据，因为他们在磁盘上是连续存储的。这种方式的缺点在于我们在文件合并的过程中会产生写放大。

为了解决这种写放大的问题和现代SSD读优化的出现，后来wisckey论文讲述key value 分离存储的优化思路。

也就是接收数据，将数据value以log的方式追加，把key在内存中排序之后，刷到磁盘，当然了，除了key它还保存了value在log中的start offset和size，从而能够在value log中找到对应的value，这样文件合并的数据只是key和一些元数据，写放大得到缓解。

当我们要查找key在0-100 的数据的时候，会查找到所有的key，然后根据里面的元数据去log中查找对应的value，很明显，这样就将原来LSM的顺序读改成了随机读，但论文建议配合使用SSD（不是机械硬盘），因为SSD的随机读和顺序读的效率差别不大，同时可以使用多线程并发查询。弥补了随机读的劣势，同时减少了文件合并的写放大。